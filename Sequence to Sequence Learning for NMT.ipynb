{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Learning for NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TranslationData(Dataset):\n",
    "    def __init__(self, file_path, reverse=False):\n",
    "        super(TranslationData, self).__init__()\n",
    "        with open(file_path) as data_file:\n",
    "            cleaned_data = data_file.read().lower().translate({**{ord(c): None for c in '.,;\"!?'} , **{ord(c): ' ' for c in '-'}, **{ord(c): \"' \" for c in \"'\"}})\n",
    "            self.pairs = [line.strip().split('\\t') for line in cleaned_data.splitlines()]\n",
    "            self.pairs = self.pairs[:50000] # Truncate data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[['go', 'va'], ['run', 'cours'], ['run', 'courez'], ['wow', 'ça alors'], ['fire', 'au feu']]\n",
      "[\"his idea wasn' t usable\", \"son idée n' était pas exploitable\"]\n"
     ]
    }
   ],
   "source": [
    "data = TranslationData(\"data/fra.txt\")\n",
    "print(len(data))\n",
    "print(data[0:5])\n",
    "print(data[40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Language():\n",
    "    def __init__(self, lines):\n",
    "        self.indices = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.words = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.count = 4\n",
    "        \n",
    "        for line in lines:\n",
    "            for word in line.split():\n",
    "                if word not in self.indices:\n",
    "                    self.indices[word] = self.count\n",
    "                    self.words[self.count] = word\n",
    "                    self.count += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6070 10952\n"
     ]
    }
   ],
   "source": [
    "english = Language([sentence[0] for sentence in data])\n",
    "french = Language([sentence[1] for sentence in data])\n",
    "print(len(english), len(french))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, src, trg):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        EMB_SIZE = 128\n",
    "        H_SIZE = 256\n",
    "        LAYERS = 2\n",
    "        self.src_emb = nn.Embedding(src.count, EMB_SIZE)\n",
    "        self.trg_emb = nn.Embedding(trg.count, EMB_SIZE)\n",
    "        self.encoder = nn.GRU(EMB_SIZE, H_SIZE, LAYERS, batch_first=True)\n",
    "        self.decoder = nn.GRU(EMB_SIZE, H_SIZE, LAYERS, batch_first=True)\n",
    "        self.to_trg = nn.Linear(H_SIZE, trg.count)\n",
    "    \n",
    "    def forward(self, src_sen_ids, trg_sen_ids):\n",
    "        src_sen_emb = self.src_emb(src_sen_ids).unsqueeze(0)\n",
    "        enc_output, enc_hidden = self.encoder(src_sen_emb)\n",
    "        trg_sen_emb = self.trg_emb(trg_sen_ids).unsqueeze(0)\n",
    "        dec_output, dec_hidden = self.decoder(trg_sen_emb, enc_hidden)\n",
    "        preds = F.log_softmax(self.to_trg(dec_output.squeeze(0)), dim=1) \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence, language, sos=False, eos=False, reverse=False, verbose=False):\n",
    "    sentence = [word if word in language.indices else \"<UNK>\" for word in sentence.split()]\n",
    "    if sos: sentence = [\"<SOS>\"] + sentence\n",
    "    if eos: sentence = sentence + [\"<EOS>\"]\n",
    "    if verbose: print(sentence)\n",
    "    if reverse: sentence = sentence[::-1]\n",
    "    ids = [language.indices[w] for w in sentence]\n",
    "    ids_var = Variable(torch.LongTensor(ids))\n",
    "    if cuda: ids_var = ids_var.cuda()\n",
    "    return ids_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_fr_model = Seq2Seq(english, french)\n",
    "if cuda: eng_fr_model.cuda()\n",
    "optimizer = optim.Adam(eng_fr_model.parameters())\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [09:36<00:00, 86.67it/s]\n",
      "100%|██████████| 50000/50000 [09:34<00:00, 87.00it/s]\n",
      "100%|██████████| 50000/50000 [09:37<00:00, 86.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    for i, pair in enumerate(tqdm(data)):\n",
    "        src_sen = prepare_sentence(pair[0], english, sos=True, reverse=True)\n",
    "        trg_sen_teacher = prepare_sentence(pair[1], french, sos=True)\n",
    "        trg_sen = prepare_sentence(pair[1], french, eos=True)\n",
    "        preds = eng_fr_model(src_sen, trg_sen_teacher)\n",
    "        loss = criterion(preds, trg_sen)\n",
    "        writer.add_scalar('data/loss', loss.data[0], i)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm(eng_fr_model.parameters(), 5.0)\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(i):\n",
    "    pair = data[i]\n",
    "    english_sentence = prepare_sentence(pair[0], english, sos=True, reverse=True, verbose=True)\n",
    "    french_sentence = prepare_sentence(pair[1], french, sos=True, verbose=True)\n",
    "    preds = eng_fr_model(english_sentence, french_sentence)\n",
    "    print([french.words[ids[0]] for ids in preds.topk(1)[1].data])\n",
    "\n",
    "def evaluate_sample(size):\n",
    "    import random\n",
    "    for i in random.sample(range(50000), size):\n",
    "        evaluate(i)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'it', 'is', 'i', 'who', 'am', 'to', 'blame']\n",
      "['<SOS>', \"c'\", 'est', 'moi', 'qui', 'suis', 'à', 'blâmer']\n",
      "[\"c'\", 'est', 'tout', 'avec', 'y', \"l'\", 'la', '<EOS>']\n",
      "\n",
      "['<SOS>', 'i', 'have', 'my', 'own', 'room']\n",
      "['<SOS>', 'je', 'dispose', 'de', 'ma', 'propre', 'chambre']\n",
      "['je', 'ma', 'que', 'ma', 'chambre', 'chambre', '<EOS>']\n",
      "\n",
      "['<SOS>', 'be', 'calm']\n",
      "['<SOS>', 'sois', 'calme']\n",
      "['soyez', 'sont', '<EOS>']\n",
      "\n",
      "['<SOS>', 'the', 'door', 'blew', 'shut']\n",
      "['<SOS>', 'la', 'porte', 'claqua', 'dans', 'un', 'souffle']\n",
      "['la', 'voiture', 'ont', '<EOS>', 'la', 'moment', '<EOS>']\n",
      "\n",
      "['<SOS>', 'i', 'doubt', 'if', 'he', 'is', 'honest']\n",
      "['<SOS>', 'je', 'doute', \"qu'\", 'il', 'soit', 'honnête']\n",
      "['je', \"n'\", \"qu'\", 'il', 'est', 'honnête', '<EOS>']\n",
      "\n",
      "['<SOS>', 'i', 'rang', 'the', 'bell']\n",
      "['<SOS>', \"j'\", 'ai', 'fait', 'sonner', 'la', 'cloche']\n",
      "['je', 'ai', 'je', 'quelque', 'le', 'raison', '<EOS>']\n",
      "\n",
      "['<SOS>', 'i', 'turned', 'on', 'the', 'radio']\n",
      "['<SOS>', \"j'\", 'ai', 'allumé', 'la', 'radio']\n",
      "[\"j'\", 'ai', 'radio', 'la', 'radio', '<EOS>']\n",
      "\n",
      "['<SOS>', \"that'\", 's', 'fantastic', 'news']\n",
      "['<SOS>', \"c'\", 'est', 'une', 'bonne', 'nouvelle']\n",
      "[\"c'\", 'est', 'toujours', 'nouvelle', 'nouvelle', 'nouvelles']\n",
      "\n",
      "['<SOS>', \"we'\", 're', 'all', 'infected']\n",
      "['<SOS>', 'nous', 'sommes', 'tous', 'infectés']\n",
      "['nous', 'sommes', 'tous', 'en', '<EOS>']\n",
      "\n",
      "['<SOS>', 'i', 'must', 'be', 'getting', 'close']\n",
      "['<SOS>', 'je', 'dois', \"m'\", 'en', 'approcher']\n",
      "['je', 'dois', 'te', 'en', 'sécurité', '<EOS>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
