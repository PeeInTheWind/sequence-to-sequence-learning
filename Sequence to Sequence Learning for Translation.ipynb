{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Learning for Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "writer = SummaryWriter()\n",
    "use_pretrained_embeddings = False\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000 1014 1000\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(lang):\n",
    "    return lambda text: [token.text for token in lang.tokenizer(text)]\n",
    "\n",
    "DE = data.Field(tokenize=tokenizer(spacy.load('de')), eos_token=\"<eos>\",\n",
    "                include_lengths=True, batch_first=True)\n",
    "EN = data.Field(tokenize=tokenizer(spacy.load('en')), init_token=\"<sos>\",\n",
    "                eos_token=\"<eos>\", include_lengths=True, batch_first=True)\n",
    "\n",
    "train, val, test = datasets.Multi30k.splits(exts=('.de','.en'), fields=(DE, EN))\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19204 10839\n"
     ]
    }
   ],
   "source": [
    "# Optionally use pretrained word vectors from FastText\n",
    "DE.build_vocab(train.src, vectors=FastText('de') if use_pretrained_embeddings else None)\n",
    "EN.build_vocab(train.trg, vectors=FastText('en') if use_pretrained_embeddings else None)\n",
    "print(len(DE.vocab), len(EN.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bi-directional 2 layer encoder, standard 4 layer decoder\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, src, trg):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        SRC_EMB_SIZE = src.vectors.size(1) if use_pretrained_embeddings else 128\n",
    "        TRG_EMB_SIZE = trg.vectors.size(1) if use_pretrained_embeddings else 128\n",
    "        H_SIZE = 256\n",
    "        LAYERS = 4\n",
    "        \n",
    "        self.src_emb = nn.Embedding(len(src), SRC_EMB_SIZE)\n",
    "        self.trg_emb = nn.Embedding(len(trg), TRG_EMB_SIZE)\n",
    "        if use_pretrained_embeddings:\n",
    "            self.src_emb.weight = nn.Parameter(src.vectors)\n",
    "            self.trg_emb.weight = nn.Parameter(trg.vectors)\n",
    "        \n",
    "        self.encoder = nn.GRU(SRC_EMB_SIZE, H_SIZE, LAYERS//2, bidirectional=True, dropout=0.2, batch_first=True)\n",
    "        self.decoder = nn.GRU(TRG_EMB_SIZE, H_SIZE, LAYERS, dropout=0.2, batch_first=True)\n",
    "        self.to_trg = nn.Linear(H_SIZE, len(trg))\n",
    "    \n",
    "    def forward(self, src_sen_ids, src_lens, trg_sen_ids):\n",
    "        src_sen_emb = self.src_emb(src_sen_ids)\n",
    "        src_sen_emb = pack_padded_sequence(src_sen_emb, src_lens, batch_first=True)\n",
    "        enc_output, enc_hidden = self.encoder(src_sen_emb)\n",
    "        \n",
    "        # Always use teacher forcing\n",
    "        trg_sen_emb = self.trg_emb(trg_sen_ids)\n",
    "        dec_output, dec_hidden = self.decoder(trg_sen_emb, enc_hidden)\n",
    "\n",
    "        preds = F.log_softmax(self.to_trg(dec_output), dim=2) \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "model = Seq2Seq(DE.vocab, EN.vocab)\n",
    "if cuda: model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Masked loss function (loss from padding not computed)\n",
    "trg_mask = torch.ones(len(EN.vocab))\n",
    "trg_mask[EN.vocab.stoi[\"<pad>\"]] = 0\n",
    "if cuda: trg_mask = trg_mask.cuda()\n",
    "criterion = nn.NLLLoss(weight=trg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterators for training and examples\n",
    "train_iter = data.BucketIterator(train, batch_size=64, sort_key=lambda ex: len(ex.src), sort_within_batch=True)\n",
    "examples = iter(data.BucketIterator(val, batch_size=1, train=False, shuffle=True, repeat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Ein Mann boxt <eos>\n",
      "= A man practices boxing <eos>\n",
      "< vibrantly paler paler neon neon\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "def compare_prediction(src_sen, trg_sen, pred_sen):\n",
    "    print(\">\", ' '.join([DE.vocab.itos[num] for num in src_sen.data[0]]))\n",
    "    print(\"=\", ' '.join([EN.vocab.itos[num] for num in trg_sen.data[0]]))\n",
    "    print(\"<\", ' '.join([EN.vocab.itos[num[0]] for num in pred_sen]))\n",
    "\n",
    "def batch_forward(batch):\n",
    "    src_sen = batch.src[0]\n",
    "    trg_sen_in = batch.trg[0][:,:-1] # skip eos\n",
    "    trg_sen = batch.trg[0][:,1:] # skip sos\n",
    "    preds = model(src_sen, batch.src[1].cpu().numpy(), trg_sen_in)\n",
    "    return src_sen, trg_sen, preds\n",
    "    \n",
    "def sample_prediction(data_iter):\n",
    "    batch = next(data_iter)\n",
    "    src_sen, trg_sen, preds = batch_forward(batch)\n",
    "    pred_sen = preds.topk(1)[1].data[0]\n",
    "    compare_prediction(src_sen, trg_sen, pred_sen)\n",
    "\n",
    "# Quick sanity check\n",
    "sample_prediction(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):    \n",
    "    scheduler.step()\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        src_sen, trg_sen, preds = batch_forward(batch)\n",
    "        loss = criterion(preds.contiguous().view(-1,preds.size(2)), trg_sen.contiguous().view(-1))\n",
    "        writer.add_scalar('data/train_loss', loss.data[0], len(train_iter)*epoch + i)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        if i == len(train_iter)-1:\n",
    "            break\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_iter = data.BucketIterator(val, batch_size=1, sort_key=lambda ex: len(ex.src), sort_within_batch=True, train=False)\n",
    "    val_loss = val_acc = 0\n",
    "    for batch in val_iter:\n",
    "        src_sen, trg_sen, preds = batch_forward(batch)\n",
    "        val_acc += preds.topk(1)[1].data[0].view(1, -1).eq(trg_sen.data).sum() / trg_sen.size(1)\n",
    "        val_loss += criterion(preds.contiguous().view(-1,preds.size(2)), trg_sen.contiguous().view(-1))\n",
    "    writer.add_scalar('data/val_loss', val_loss/len(val_iter), epoch)\n",
    "    writer.add_scalar('data/val_acc', val_acc/len(val_iter), epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_predictions(num):\n",
    "    for i in range(num):\n",
    "        sample_prediction(examples)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Kinder fahren in einem Kettenkarussell <eos>\n",
      "= Kids are riding a swinging carnival ride <eos>\n",
      "< Children are riding in ride in in .\n",
      "\n",
      "> Junge macht Kunststücke auf einem Skateboard <eos>\n",
      "= Boy doing tricks on a skateboard <eos>\n",
      "< Young doing tricks on a skateboard .\n",
      "\n",
      "> Ein Künstler malt im Freien . <eos>\n",
      "= An artist is painting outside . <eos>\n",
      "< An artist is outside outside . <eos>\n",
      "\n",
      "> Zwei Menschen überqueren eine Straße . <eos>\n",
      "= Two people walking across a street . <eos>\n",
      "< Two people are down a street . <eos>\n",
      "\n",
      "> Drei Hunde spielen im Schnee . <eos>\n",
      "= Three dogs playing in the snow . <eos>\n",
      "< Three dogs play in the snow . <eos>\n",
      "\n",
      "> Sie posieren für ein Bild . <eos>\n",
      "= They are posing for a picture . <eos>\n",
      "< They are posing for a picture . <eos>\n",
      "\n",
      "> Eine Person trägt viele Taschen . <eos>\n",
      "= A person is carrying many bags . <eos>\n",
      "< A person is wearing a balls . <eos>\n",
      "\n",
      "> Ein Snowboarder vollführt ein Kunststück . <eos>\n",
      "= A snowboarder is doing a trick . <eos>\n",
      "< A snowboarder doing doing a trick . <eos>\n",
      "\n",
      "> Die Frau hält eine Geige . <eos>\n",
      "= The woman is holding a violin . <eos>\n",
      "< The woman is holding a speech . <eos>\n",
      "\n",
      "> Ein Künstler arbeitet an einer Eisskulptur <eos>\n",
      "= An artist working on an ice sculpture <eos>\n",
      "< An artist working on a outdoor cream .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_predictions(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
